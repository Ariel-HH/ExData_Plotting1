d <- Sys.Date()
format(d, "%a %b %Y")
Sys.setlocale("LC_TIME", "C")
format(d, "%a %b %Y")
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
play()
Sys.setlocale("en_US.UTF-8")
Sys.setlocale(en_US.UTF-8)
Sys.setlocale("LC_TIME", "en_US.UTF-8")
nxt()
help(package = lubridate)
this_day <- today()
this_day
day(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920\1\2")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours= 17 , minutes = 34, seconds= 22)
this_moment
nyc <- now(tzone = "America/New_York")
nyc
nyc+days(2)
depart <- nyc+days(2)
depart
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart+hours(15)+minutes(50)
?with_tz
with_tz
with_tz(arrive, "Asia/Hong_Kong")
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy(June, 17, 2008, tz = "Singapore")
last_time <- mdy("June, 17, 2008", tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
##############
##############
############## Question 1
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url, "housing_Idaho.csv")
##############
##############
############## Question 1
library(data.table)
dat <- fread("housing_Idaho.csv")
View(dat)
names(dat)
answ <- strsplit(names(dat), "wgtp")
answ[123]
answ <- strsplit(names(dat), "[wgtp]")
answ[123]
answ <- strsplit(names(dat), "wgtp")
answ[123]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "GDP190.csv")
gdp <- fread("GDP190.csv")
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
##############
##############
############## Question 2
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "GDP190.csv")
gdp <- fread("GDP190.csv")
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
gdp <- fread("GDP190.csv"); eduGDP <- fread("educationalGDP.csv")
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(gdp$V2)))
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(gdp$V2)))
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
gdp <- fread("GDP190.csv"); eduGDP <- fread("educationalGDP.csv")
##############
##############
############## Question 1
library(dplyr)
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
View(eduGDP)
View(gdp)
library(dplyr)
library(dplyr)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "GDP190.csv")
gdp <- fread("GDP190.csv")
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
V5num <- as.numeric(gsub(",", "", gdp$V5))
mean(V5num)
##############
##############
############## Question 2
grep("^United",gdp$V4)
##############
##############
############## Question 2
grep("^United",gdp$V4, value = T)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "GDP190.csv")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, "educationalGDP.csv")
gdp <- fread("GDP190.csv"); eduGDP <- fread("educationalGDP.csv")
# as gdp contains not ranked obs we filter as follows
gdp <- filter(gdp, !is.na(as.numeric(V2)))
# now we merge
datMerged <- merge(gdp, eduGDP, by.x = "V1", by.y = "CountryCode")
View(datMerged)
datMerged$`Special Notes`
availNotes <- datMerged$`Special Notes`[which(nchar(datMerged$`Special Notes`)>0)]
availNotes
grep("Fiscal year end: June", availNotes)
length(grep("Fiscal year end: June", availNotes))
length(grep("June", availNotes))
length(grep("Fiscal year end:June", availNotes))
length(grep("Fiscal year end: June", availNotes))
length(grep("Fiscal year end: [Jj]une", availNotes))
length(grep("[Ff]iscal year end: [Jj]une", availNotes))
length(grep("Fiscal year end: June", availNotes, ignore.case = T))
##############
##############
############## Question 5
library(quantmod)
install.packages(quantmod)
install.packages("quantmod")
##############
##############
############## Question 5
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
library(lubridate)
year(sampleTimes)
length(which(year(sampleTimes)==2012))
length(which(day(sampleTimes)==2))
length(which(year(sampleTimes)==2012&day(sampleTimes)==2))
length(which(year(sampleTimes)==2012 & wday(sampleTimes)=="mon"))
day(sampleTimes)==2
day(sampleTimes)
length(which(year(sampleTimes)==2012 & wday(sampleTimes)==2))
length(which(year(sampleTimes)==2012))
length(which(year(sampleTimes)==2012 & wday(sampleTimes)==2))
pkgs = c("rvest", "magrittr", "httr", "stringr")
for (pkg in pkgs){
library(pkg, character.only = TRUE)
}
doc <- read_html("http://cambiopesodolar.com.mx/dolar-hoy-en-aeropuerto-de-df/")
a <- html_nodes(doc, ".entry")
b <- html_text(a)
c <- regexpr("pesos en promedio", b)
keep = substr(b, c-7, c+16)
str_c("DÃ³lar en aeropuerto ",keep)
url = "http://www.banco-metropolitano.com.cu/"
download.file(url, destfile = "scrapedpage.html", quiet=TRUE)
content <- read_html("scrapedpage.html")
a <- html_nodes(content, ".wpb_wrapper table")
b <- html_text(a)
pos <- regexpr("19,394880", b)
keep = substr(b, 430, 436)
str_c("Precio de cuc en el BMLH $",keep)
t <- readLines("manuscript.txt")
tcop <- t
gsub("_([^ ]+)", "_{\1}", t, fixed = F)
gsub("_([^ ]+)", "_\{\1\}", t, fixed = F)
gsub("_([^ ]+)", "_\\{\1\\}", t, fixed = F)
gsub("_([^ ]+)", "_{(\1)}", t, fixed = F)
toy <- "E_1"
gsub("_([^ ]+)", "_{\1}", toy, fixed = F)
toy <- "E_1 H_1"
gsub("_([^ ]+)", "_{\1}", toy, fixed = F)
toy <- "E_ca H_1"
gsub("_([^ ]+)", "_{\1}", toy, fixed = F)
gsub("_([^ ]+)", "_{\\1}", toy, fixed = F)
gsub("_([^ ]+)", "_{\\1}", t, fixed = F)
gsub("_([a-zA-Z0-9^ ]+)", "_{\\1}", t, fixed = F)
gsub("_([a-zA-Z0-9(^ )]+)", "_{\\1}", t, fixed = F)
gsub("_([a-zA-Z0-9]+)", "_{\\1}", t, fixed = F)
gsub("\^([a-zA-Z0-9\\]+)", "\^{\\1}", t, fixed = F)
gsub("^([a-zA-Z0-9\\]+)", "^{\\1}", t, fixed = F)
gsub("(^)([a-zA-Z0-9\\]+)", "^{\\1}", t, fixed = F)
gsub("(^)([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
gsub("(^)([a-zA-Z0-9\\]+)", "\^{\\1}", toy, fixed = F)
gsub("(^)([a-zA-Z0-9\\]+)", "(^){\\1}", toy, fixed = F)
toy <- "E^ca H^\\pm" # to check what works
gsub("(^)([a-zA-Z0-9\\]+)", "(^){\\1}", toy, fixed = F)
gsub("^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
gsub("\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- "weifj     E^ca H^\\pm" # to check what works
gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
gsub(".^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
tcop <- gsub("_([a-zA-Z0-9]+)", "_{\\1}", t, fixed = F)
tcop <- gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
writeLines(tcop, "modifiedManuscript.txt")
tcop <- gsub("_([a-zA-Z0-9]+)", "_{\\1}", t, fixed = F)
tcop <- gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", t, fixed = F)
writeLines(tcop, "modifiedManuscript.txt")
toy <- "weifj     E_ca$ H^\\pm" # to check what works
tcop <- gsub("_([a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F)
gsub("_([a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F)
toy <- "weifj     E_ca$ H^\\pm$" # to check what works
gsub("_([a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- gsub("_([a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- gsub("_({}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([{}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- gsub("_(\{\}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([\{\}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- gsub("_(\\{\\}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- "weifj     E_ca$ H^\\tilde{F}$" # to check what works
toy <- gsub("_(\\{\\}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- gsub("_([\\{\\}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
toy <- "weifj     $E_ca$ H^\\tilde{F}$" # to check what works
toy <- gsub("_([\\{\\}a-zA-Z0-9]+)", "_{\\1}", toy, fixed = F);gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", toy, fixed = F)
t <- readLines("manuscript.txt")
tcop <- t
tcop <- gsub("_([\\{\\}a-zA-Z0-9]+)", "_{\\1}", tcop, fixed = F)
tcop <- gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", tcop, fixed = F)
writeLines(tcop, "modifiedManuscript.txt")
t <- readLines("manuscript.txt")
tcop <- t
tcop <- gsub("_([\\{\\}a-zA-Z0-9]+)", "_{\\1}", tcop, fixed = F)
tcop <- gsub("\\^([\\{\\}a-zA-Z0-9\\]+)", "^{\\1}", tcop, fixed = F)
writeLines(tcop, "modifiedManuscript.txt")
library(utils)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
getwd()
## create and set working dir
if(!file.exists("./data")){dir.create("./data")}
setwd("./data")
## Downloading and unziping
library(utils)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, destfile = "Dataset.zip")
unzip("Dataset.zip")
direct <- dir() #see what is in working dir
## Reading data
setwd(paste0("./", direct[2]))
library(data.table); library(dplyr)
features <- fread("features.txt")
activities <- fread("activity_labels.txt")
trainLabels <- fread("train/y_train.txt")
testLabels <- fread("test/y_test.txt")
trainSubjects <- fread("train/subject_train.txt")
testSubjects <- fread("test/subject_test.txt")
# Filtering the measurements on the mean and standard deviation
featureSelector <- grep("([Mm]ean|[Ss]td)", features$V2)
# Reading only the selected features on the train|test-sets
trainSet <- fread("train/X_train.txt", select = featureSelector)
testSet <- fread("test/X_test.txt", select = featureSelector)
## Creating a first data set with all the information
# Creating an activity vectors with descriptive activities names
trainActivities <- activities[trainLabels$V1, 2]
testActivities <- activities[testLabels$V1, 2]
# Merging the data (we don't keep train|test-labels because they contain the same info that train|test-activities)
trainData <- cbind(trainSet, trainActivities, trainSubjects)
testData <- cbind(testSet, testActivities, testSubjects)
dataSet <- rbind(trainData, testData)
# Asigning names
names(dataSet) <- c(features$V2[featureSelector], "activityName", "subjectID")
## Creating the second (independent) tidy data set with the average of each
## variable for each activity and each subject
secondDataSet <- dataSet[, lapply(.SD, mean), by = .(activityName, subjectID)]
setwd("./data")
direct <- dir() #see what is in working dir
setwd(paste0("./", direct[2]))
direct
getwd
getwd()
## Reading data
library(data.table)
features <- fread("features.txt")
activities <- fread("activity_labels.txt")
trainLabels <- fread("train/y_train.txt")
testLabels <- fread("test/y_test.txt")
trainSubjects <- fread("train/subject_train.txt")
testSubjects <- fread("test/subject_test.txt")
# Filtering the measurements on the mean and standard deviation
featureSelector <- grep("([Mm]ean|[Ss]td)", features$V2)
# Reading only the selected features on the train|test-sets
trainSet <- fread("train/X_train.txt", select = featureSelector)
testSet <- fread("test/X_test.txt", select = featureSelector)
## Creating a first data set with all the information
# Creating an activity vectors with descriptive activities names
trainActivities <- activities[trainLabels$V1, 2]
testActivities <- activities[testLabels$V1, 2]
# Merging the data (we don't keep train|test-labels because they contain the same info that train|test-activities)
trainData <- cbind(trainSet, trainActivities, trainSubjects)
testData <- cbind(testSet, testActivities, testSubjects)
dataSet <- rbind(trainData, testData)
# Asigning names
names(dataSet) <- c(features$V2[featureSelector], "activityName", "subjectID")
## Creating the second (independent) tidy data set with the average of each
## variable for each activity and each subject
secondDataSet <- dataSet[, lapply(.SD, mean), by = .(activityName, subjectID)]
View(secondDataSet)
## Reading data
library(data.table)
features <- fread("features.txt")
activities <- fread("activity_labels.txt")
trainLabels <- fread("train/y_train.txt")
testLabels <- fread("test/y_test.txt")
trainSubjects <- fread("train/subject_train.txt")
testSubjects <- fread("test/subject_test.txt")
# Filtering the measurements on the mean and standard deviation
featureSelector <- grep("([Mm]ean|[Ss]td)", features$V2)
# Reading only the selected features on the train|test-sets
trainSet <- fread("train/X_train.txt", select = featureSelector)
testSet <- fread("test/X_test.txt", select = featureSelector)
## Creating a first data set with all the information
# Creating an activity vectors with descriptive activities names
trainActivities <- activities[trainLabels$V1, 2]
testActivities <- activities[testLabels$V1, 2]
# Merging the data (we don't keep train|test-labels because they contain the same info that train|test-activities)
trainData <- cbind(trainSet, trainActivities, trainSubjects)
testData <- cbind(testSet, testActivities, testSubjects)
dataSet <- rbind(trainData, testData)
# Asigning names
names(dataSet) <- c(features$V2[featureSelector], "activity", "subjectID")
## Creating the second (independent) tidy data set with the average of each
## variable for each activity and each subject
secondDataSet <- dataSet[, lapply(.SD, mean), by = .(activity, subjectID)]
View(secondDataSet)
getwd()
## It is assumed that all the files to read are already in the working directory.
## If not, it can be done with the following code:
# ## create and set working dir
# if(!file.exists("./data")){dir.create("./data")}
# setwd("./data")
#
#
# ## Downloading and unziping
# library(utils)
# url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
# download.file(url, destfile = "Dataset.zip")
# unzip("Dataset.zip")
# setwd(paste0("./", dir()[2]))
## Reading data
library(data.table)
features <- fread("features.txt")
activities <- fread("activity_labels.txt")
trainLabels <- fread("train/y_train.txt")
testLabels <- fread("test/y_test.txt")
trainSubjects <- fread("train/subject_train.txt")
testSubjects <- fread("test/subject_test.txt")
# Filtering the measurements on the mean and standard deviation
featureSelector <- grep("([Mm]ean|[Ss]td)", features$V2)
# Reading only the selected features on the train|test-sets
trainSet <- fread("train/X_train.txt", select = featureSelector)
testSet <- fread("test/X_test.txt", select = featureSelector)
## Creating a first data set with all the information
# Creating an activity vectors with descriptive activities names
trainActivities <- activities[trainLabels$V1, 2]
testActivities <- activities[testLabels$V1, 2]
# Merging the data (we don't keep train|test-labels because they contain the same info that train|test-activities)
trainData <- cbind(trainSet, trainActivities, trainSubjects)
testData <- cbind(testSet, testActivities, testSubjects)
dataSet <- rbind(trainData, testData)
# Asigning descriptive names
names(dataSet) <- c(features$V2[featureSelector], "activity", "subjectID")
## Creating the second (independent) tidy data set with the average of each
## variable for each activity and each subject
secondDataSet <- dataSet[, lapply(.SD, mean), by = .(activity, subjectID)]
View(secondDataSet)
library(data.table); library(dplyr)
dt <- data.table(a=c(1,0,0), b=c(0,1,0), c=c(0,0,1))
melt(dt, id.vars = 1:3)
melt(dt, id.vars = 1:2)
melt(dt)
dt <- data.table(a=c(1,NA,NA), b=c(NA,1,NA), c=c(NA,NA,1))
melt(dt)
melt(dt, na.rm = T)
dt <- data.table(a=c(1,NA,0), b=c(NA,1,NA), c=c(NA,NA,1))
melt(dt, na.rm = T)
melt(dt, na.rm = T) %<% dcast()
melt(dt, na.rm = T) %>% dcast()
melt(dt, na.rm = T) %>% dcast(formula = variable~value)
source("best.R")
source("rankhospital.R")
source("rankall.R")
outcome[, 11] <- as.numeric(outcome[, 11])
## You may get a warning about NAs being introduced; that is okay
hist(outcome[, 11])
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
getwd()
View(dt)
setwd("../")
getwd()
setwd("../")
getwd()
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
outcome[, 11] <- as.numeric(outcome[, 11])
## You may get a warning about NAs being introduced; that is okay
hist(outcome[, 11])
View(outcome)
## create and set working dir
if(!file.exists("./data_power_consumption")){dir.create("./data_power_consumption")}
setwd("./data_power_consumption")
## Downloading and unziping
library(utils)
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
download.file(url, destfile = "household_power_consumption.zip")
unzip("household_power_consumption.zip")
dir()
library(data.table)
consumption <- fread("household_power_consumption.txt")
head(consumption, 3)
tail(consumption, 3)
object.size(consumption)
object.size(consumption, units="Mb")
object.size(consumption, units="MB")
object.size(consumption, units="MB", standard="legacy")
dat <- fread("../new 1.txt")
View(dat)
rm("dat", "url")
View(consumption)
str(consumption)
getwd()
setwd("C:/Users/Latitude/ExData_Plotting1/")
getwd()
png("plot1.png")
hist(consumption$Global_active_power, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
hist(consumption$Global_active_power, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
gap <- as.numeric(consumption$Global_active_power)
any(gap==NA)
any(is.na(gap))
which(is.na(gap))
table(is.na(gap))
gap <- as.numeric(consumption$Global_active_power, na.omit=T)
table(is.na(gap))
gap <- as.numeric(consumption$Global_active_power); gap <- gap[!is.na(gap)]
table(is.na(gap))
hist(, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
# Creating the plot
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
# Closing the devise
dev.off()
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
axis(2, at=seq(0, 1200, by=200))
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
# Getting consumption$Global_active_power data without missing values
gap <- as.numeric(consumption$Global_active_power)
# Creating the plot
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red")
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red", axis=F)
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red", axes=F)
axis(2, at=seq(0, 1200, by=200))
seq(0, 1200, by=200)
axis(2, at=seq(0, 1200, by=200))
axis(2, seq(0, 1200, by=200))
class(seq(0, 1200, by=200))
axis(2)
axis(2, c(0, 200, 1200))
plot(1:4, rnorm(4), axes = FALSE)
axis(1, 1:4, LETTERS[1:4])
axis(2)
# Creating the plot
hist(gap, xlab = "Global Active Power (kilowatts)",
main = "Global Active Power", col = "red", axes=F)
axis(2, seq(0, 1200, by=200), seq(0, 1200, by=200))
summary(gap)
gap <- as.numeric(consumption$Global_active_power)
gap <- gap[!is.na(gap)]
summary(gap)
library(data.table); library(dplyr)
library(data.table); library(dplyr), library(lubridate)
consumption <- consumption[, Date = dmy(Date), Time = hms(Time)]
consumption <- consumption[,.(Date = dmy(Date), Time = hms(Time))]
dmy(consumption$Date)
library(lubridate)
dmy(consumption$Date)
consumption <- consumption[,.(Date = dmy(Date), Time = hms(Time))]
str(consumption)
consumption <- fread("household_power_consumption.txt")
